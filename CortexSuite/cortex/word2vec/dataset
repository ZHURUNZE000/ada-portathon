The various datasets required for this algorithm are as follows:

http://www.statmt.org/wmt14/training-monolingual-news-crawl/news.2013.en.shuffled.gz

http://www.statmt.org/wmt14/training-monolingual-news-crawl/news.2012.en.shuffled.gz

http://www.statmt.org/lm-benchmark/1-billion-word-language-modeling-benchmark-r13output.tar.gz

http://ebiquity.umbc.edu/redirect/to/resource/id/351/UMBC-webbase-corpus

http://dumps.wikimedia.org/enwiki/latest/enwiki-latest-pages-articles.xml.bz2

wget http://mattmahoney.net/dc/text8.zip -O text8.gz


